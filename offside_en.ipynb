{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Model to Detect Offsides in a Football Match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it possible to teach a computer the most complex rule of football, the offside, by using very simple models and data from a single game?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Offside "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A player is in an \"offside position\" if they are in the opposing team's half of the field and also \"nearer to the opponents' goal line than both the ball and the second-last opponent.\" This is a brief description, and we can develop it a little further by stating the five conditions that must be met.<br>\n",
    "1. A teammate touches the ball, either by a pass, a headbutt or kicking towards the goal;\n",
    "2. The pass is not from a corner kick, a goal kick or a throw-in;\n",
    "3. The receiving player is in the offensive half of the field;\n",
    "4. The receiving player is closer to the goal line than the ball;\n",
    "5. There is only one player from the other team between the receiving player and the goal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all five conditions happen in a given play, the game must be stopped and a free kick is given to the defensive team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Learning by Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to create a model where these rules are not explicitly written, but are learned from a data set of annotated plays. That is, we are going to feed the model with a series of plays, with the position of the 22 players, 11 for each team, the player who is passing the ball and the receiver, with a label \"offside\" or \"no_offside\". We will evaluate the model afterwards to see how good is the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found some collections of data with offsides, but they didn't include the position of the players. Furthermore, we also needed data for the cases where no offside happened. There were two possible paths:\n",
    "1. create a large number of plays by choosing randomly the position for all the players;\n",
    "2. find real data from, at least, one football match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros: very easy to create a large number of plays.<br>\n",
    "Cons: most of the plays are unrealistic for a football match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** too much junk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pros: real situations from a football match.<br>\n",
    "Cons: very hard data to find; data cleaning necessary; possible need for data augmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jackpot:** we found **ONE** match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have found a data set called <a href=\"https://old.datahub.io/dataset/magglingen2013\">Magglingen2013</a>.<br> \n",
    "*Recorded position data of professional football matches. The data includes positions on football field in 100ms steps (10Hz) of the players, and the ball.*<br>\n",
    "*The games were performed in real competition situation by top swiss football club players (U19). The data was intentionally anonymized, not at last because of the high density of information available.*<br>\n",
    "*This dataset gives you a glimpse on a possible data stream originating from a live match in some not to distant future.*<br>\n",
    "*The terrain was an artificial green. Recordings are available from beginning of the first half time up to the end to the second half time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two matches listed at this website, but the links are broken. We were able to find the file for \"*Game TR vs. FT*\", so we are using that as our initial data set. The file is a JSON file, with a timestamp and, for each player, an identifier, the coordinates on the field (x,y), the distance to the ball and if he has the possession of the ball."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"json.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a second JSON file, matching the player ID with one of the two teams, and another ID for the ball itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"json2.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand a little better the data before we try any cleaning. For example, we need to find out the size of the field to be able to find anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print('Loading data')\n",
    "\n",
    "#reading game data\n",
    "print('Reading game data')\n",
    "filename='tr-ft.json'\n",
    "with open(filename) as json_file:\n",
    "    data_game = json.load(json_file)\n",
    "\n",
    "#reading team players\n",
    "print('Reading team data')\n",
    "filename2='tr-ft-gamedesc.json'    \n",
    "with open(filename2) as json_file:\n",
    "    data_teams = json.load(json_file)\n",
    "\n",
    "data_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the IDs for each player. In the next step, we will create a list with the teams, first the eleven player from *Team 1*, then eleven players from *Team 2*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of players, 11 for team 1, 11 for team 2\n",
    "lineup=[]\n",
    "for i in data_teams['player'].keys():\n",
    "    teams=[i,data_teams['player'][i]['team']]\n",
    "    \n",
    "    lineup.append(teams)\n",
    "\n",
    "lineup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID **5** is the ball. The IDs are ordered by team, so we don't need the second column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineup = [ item for elem in lineup for item in elem]\n",
    "lineup = lineup[::2]\n",
    "lineup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we processed the team data, let's take a look at the game data. As we have showed before, for each instant we have the position of the ball and of the 22 players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_game[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a DataFrame where the first column is the timestamp and then the position for the ball and each one of the players, in the order of the lineup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "events = []\n",
    "for ii in range(len(data_game)):\n",
    "    new_play = [data_game[ii]['ts']]\n",
    "    positions = []\n",
    "    for jj in range(len(data_game[ii]['data'])):\n",
    "        position_player = [data_game[ii]['data'][jj]['id']]\n",
    "        position_player.append(data_game[ii]['data'][jj]['x'])\n",
    "        position_player.append(data_game[ii]['data'][jj]['y'])\n",
    "        positions.append(position_player)\n",
    "    \n",
    "    for kk in lineup:\n",
    "        temp_x = np.nan\n",
    "        temp_y = np.nan    \n",
    "        for ll in range(len(positions)):\n",
    "            if int(kk) == positions[ll][0]:\n",
    "                temp_x = positions[ll][1]\n",
    "                temp_y = positions[ll][2]\n",
    "        new_play.append(temp_x)\n",
    "        new_play.append(temp_y)\n",
    "\n",
    "    events.append(new_play)\n",
    "\n",
    "print('Number of frames of the game: ',len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_events=['timestamp']\n",
    "for ii in range(len(lineup)):\n",
    "    columns_events.append('x_'+lineup[ii])\n",
    "    columns_events.append('y_'+lineup[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_events = pd.DataFrame(events, columns=columns_events)\n",
    "df_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a DataFrame where each row is the configuration of players in the field at a given instant. Our data fas a 10Hz frequency, that is, we have 10 row for each second. We can see there is very little variation from one row to the next. <br>\n",
    "Let's have a quick look at some statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to get rid of those '99999.999' values and replace them with NaN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = df_events.replace([99999.999],np.nan)\n",
    "df_events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this first clean up, we can see the columns x_5 and y_5 had a huge drop in the count, at 48908 from the original 68031. That means we don't have the location of the ball for 31 minutes and 52.3 seconds, but the data is available for 81 minutes and 30.8 seconds, consistent with a match duration of 90 minutes. There must be some events where the ball is out of bounds that add up to the missing time. <br>\n",
    "The position of the players also have a drop in the count, what probably must be related to the half time break. <br>\n",
    "Let's take a look at the distribution of (X,Y) for all the players. We will create histograms to try to determine the length and width of the field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_x = []\n",
    "list_of_y = []\n",
    "for column in columns_events:\n",
    "    if column[:2] == 'x_':\n",
    "        list_of_x.append(df_events[column].tolist())\n",
    "    elif column[:2] == 'y_':\n",
    "        list_of_y.append(df_events[column].tolist())\n",
    "\n",
    "list_of_x = [ item for elem in list_of_x for item in elem]\n",
    "list_of_y = [ item for elem in list_of_y for item in elem]\n",
    "print('X: ',list_of_x[:10])\n",
    "print('Y: ',list_of_y[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from the description of the position of the ball\n",
    "x_min = -52\n",
    "x_max = 52\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.linspace(10*x_min, 10*x_max, 1050) # fixed bin size\n",
    "\n",
    "plt.xlim([min(list_of_x), max(list_of_x)])\n",
    "plt.title('Distribution of X (m)')\n",
    "plt.xlabel('X (bin size = 1m)')\n",
    "plt.ylabel('count')\n",
    "plt.hist(list_of_x, bins=bins, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we need to clean more of the data. Most of the data is within the range of positions for the ball, (-52,52), which we got from the table describing the columns. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([-60, 60])\n",
    "plt.title('Distribution of X (m)')\n",
    "plt.xlabel('X (bin size = 1m)')\n",
    "plt.ylabel('count')\n",
    "plt.hist(list_of_x, bins=bins, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram, we learn two things:\n",
    "1. The X position is in the direction of the length of the field, with the center at 0 and the goal lines at +/- 52m;\n",
    "2. We need to clean more data, getting rid of all the positions where the players are more than 2 meters off the field (to allow corner kicks and the goalies retrieving the ball)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the description of the position of the ball\n",
    "y_min = -34\n",
    "y_max = 34\n",
    "\n",
    "# fixed bin size\n",
    "bins = np.linspace(10*y_min, 10*y_max, 1050) # fixed bin size\n",
    "\n",
    "plt.xlim([min(list_of_y), max(list_of_y)])\n",
    "plt.title('Distribution of Y (m)')\n",
    "plt.xlabel('Y (bin size = 1m)')\n",
    "plt.ylabel('count')\n",
    "plt.hist(list_of_y, bins=bins, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we need to clean more of the data. Most of the data is within the range of positions for the ball, (-34,34), which we got from the table describing the columns. Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlim([-40, 40])\n",
    "plt.title('Distribution of Y (m)')\n",
    "plt.xlabel('Y (bin size = 1m)')\n",
    "plt.ylabel('count')\n",
    "plt.hist(list_of_y, bins=bins, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this histogram, we learn two things:\n",
    "1. The Y position is in the direction of the width of the field, with the center at 0 and the side lines at +/- 34m;\n",
    "2. We need to clean more data, getting rid of all the positions where the players are more than 2 meters off the field (to allow the throw-ins)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are replacing every X over +/- 54 and every Y over +/- 36 with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_events:\n",
    "    if column[:2] == 'x_':\n",
    "        df_events[column].loc[df_events[column] < -54] = np.nan\n",
    "        df_events[column].loc[df_events[column] > 54] = np.nan\n",
    "    if column[:2] == 'y_':\n",
    "        df_events[column].loc[df_events[column] < -36] = np.nan\n",
    "        df_events[column].loc[df_events[column] > 36] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have all the (x,y) inside the field plus a 2m margin. But we have a new problem: we have a different number of values for x and y for a single player, and different numbers for each player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_events:\n",
    "    print(column,': ',df_events[column].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower count is for player 16, with around 42.000 rows. He was probably sent off at the start of the second half or was injured.<br>\n",
    "We have two options:\n",
    "1. Fill in the gaps in the data, with an average position or a new random location;\n",
    "2. Remove all the rows with missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the distribution of these gaps during the game. The ball gets out of the field regularly, so we won't use its position in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nans=[]\n",
    "number_frames_nan=0\n",
    "sequence_of_nans=0\n",
    "df_nans=df_events.drop(['x_5', 'y_5'], axis=1).isna()\n",
    "for ii in range(len(df_events)):\n",
    "    count_nan=df_nans.loc[[ii]].sum().sum()\n",
    "    if count_nan>0:\n",
    "        number_frames_nan += 1\n",
    "        sequence_of_nans += 1\n",
    "        if sequence_of_nans > 40:\n",
    "            sequence_of_nans = 40\n",
    "    else:\n",
    "        sequence_of_nans = 0\n",
    "    nans.append(sequence_of_nans)\n",
    "print('Number of frames with NaN: ',number_frames_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Sequence of frames with NaN')\n",
    "plt.xlabel('Frames')\n",
    "plt.ylabel('Number of frames with NaN in sequence')\n",
    "plt.scatter(range(len(df_events)),nans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to read the above plot: most of the time we have full data. In the first half, there is an event with 4 rows in a sequence with at least one NaN, another sequence with 12 rows, another with 7 rows, and one with 24 rows. Then we see the end of the first half and the return of the game. We see four sequences (with 6, 20, 8 and 35). After these events, we see what was expected: one player is out for the remainder of the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three different groups:\n",
    "1. Half-time\n",
    "2. One player out\n",
    "3. Problematic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important here to remember that the data has a frequency of 10Hz. A sequence of 35 rows, our largest sequence, is equivalent to 3.5 seconds of the game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To keep things simple, we can get rid of all the time frames with incomplete data without compromising our analysis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do that, let's make a transformation that will simplify our work later on. The teams trade sides for the second half. We will flip the data for the second half, multiplying them by *-1*, so that the team's offensive half is always the same, *team 1* attacking to the right and *team 2* to the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(int(len(df_events)/2),len(df_events)):\n",
    "    df_events.loc[ii]=-1*df_events.loc[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the original 68031 frames, we have 27505 incomplete rows. This leaves information for 40526 frames, equivalent to 67 minutes and 32 seconds, about 75% of a match. Good enough for us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_clean=df_events.dropna(subset=columns_events[3:]).reset_index(drop=True)\n",
    "df_events_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally have a clean data set to start our project, with 40526 frames with the position of 22 players in real game situations. Let's create a function to show a random row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_clean.to_csv('df_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Create field\n",
    "fieldx=[]\n",
    "fieldy=[]\n",
    "for i in range(-5200,5200,10):\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(-3400)\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(3400)\n",
    "\n",
    "for i in range(-3400,3400,10):\n",
    "    fieldx.append(-5200)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(5200)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(0)\n",
    "    fieldy.append(i)\n",
    "\n",
    "for i in range(360):\n",
    "    fieldx.append(915*math.cos(math.radians(i)))\n",
    "    fieldy.append(915*math.sin(math.radians(i)))\n",
    "\n",
    "for i in range(0,2016,10):\n",
    "    fieldx.append(5200-1650)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(5200-1650)\n",
    "    fieldy.append(-i)\n",
    "    fieldx.append(-5200+1650)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(-5200+1650)\n",
    "    fieldy.append(-i)\n",
    "\n",
    "for i in range(5200,5200-1650,-10):\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(2016)\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(-2016)\n",
    "    fieldx.append(-i)\n",
    "    fieldy.append(-2016)\n",
    "    fieldx.append(-i)\n",
    "    fieldy.append(2016)\n",
    "\n",
    "for i in range(0,366+550,10):\n",
    "    fieldx.append(5200-550)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(5200-550)\n",
    "    fieldy.append(-i)\n",
    "    fieldx.append(-5200+550)\n",
    "    fieldy.append(i)\n",
    "    fieldx.append(-5200+550)\n",
    "    fieldy.append(-i)\n",
    "\n",
    "for i in range(5200,5200-550,-10):\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(366+550)\n",
    "    fieldx.append(i)\n",
    "    fieldy.append(-366-550)\n",
    "    fieldx.append(-i)\n",
    "    fieldy.append(-366-550)\n",
    "    fieldx.append(-i)\n",
    "    fieldy.append(366+550)\n",
    "\n",
    "for i in range(360):\n",
    "    if 5200-1100 + 915*math.cos(math.radians(i))<52-1650:\n",
    "        fieldx.append(52-11 + 915*math.cos(math.radians(i)))\n",
    "        fieldy.append(915*math.sin(math.radians(i)))\n",
    "\n",
    "for i in range(360):\n",
    "    if -5200+1100 + 915*math.cos(math.radians(i))>-5200+1650:\n",
    "        fieldx.append(-5200+1100 + 915*math.cos(math.radians(i)))\n",
    "        fieldy.append(915*math.sin(math.radians(i)))\n",
    "\n",
    "fieldx.append(5200-1100)\n",
    "fieldy.append(0)\n",
    "fieldx.append(-5200+1100)\n",
    "fieldy.append(0)\n",
    "\n",
    "def plot_field(index):\n",
    "    #getting data for the teams\n",
    "    g1 = (100*df_events_clean.loc[index,'x_5'],100*df_events_clean.loc[index,'y_5'])\n",
    "    g2 = (100*df_events_clean.loc[index,columns_events[3:25:2]],100*df_events_clean.loc[index,columns_events[4:25:2]])\n",
    "    g3 = (100*df_events_clean.loc[index,columns_events[25::2]],100*df_events_clean.loc[index,columns_events[26::2]])\n",
    "    data = (g2,g3,g1)\n",
    "    colors = (\"red\", \"blue\",\"green\")\n",
    "    groups = (\"team1\", \"team2\", \"ball\")\n",
    "    size=(30,30,50)\n",
    "\n",
    "    # Create plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    plt.scatter(fieldx,fieldy,s=5,c=\"black\",alpha=0.3)    \n",
    "\n",
    "    for data, color, group, size in zip(data, colors, groups, size):\n",
    "        x, y = data\n",
    "        ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=size, label=group)\n",
    "\n",
    "    plt.ylim(-3700, 3700)\n",
    "    plt.xlim(-5500, 5500)\n",
    "    plt.title('Time frame: '+str(index))\n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "np.random.seed(0)\n",
    "plot_field(random.randint(0, len(df_events_clean)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some frames without the ball, but that is expected. In most of frames we can see clearly the two goalies and that we players gather around the ball. As stated before, *team 1* attacks to the right and *team 2* attacks to the left. With these plots, we can assure our data represents actual game plays and we can move on to data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more than 40 thousand situations, but let's pump up those numbers! We will create new data by adding noise to the positions of the players. By doing this, we are getting new plays, keeping them similar to real ones. For each row in our data set, we will add a small random contribution for the position of every player. We will get rid of the 'timestamp' column because this won't be used. We can also remove the columns for the ball, as we will use the position of the passing and the receiving plyers on our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plays = df_events_clean.drop(columns=['timestamp','x_5','y_5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition = 2\n",
    "df_plays_rep = df_plays.copy()\n",
    "for ii in range(repetition):\n",
    "    df_noise = pd.DataFrame(4*np.random.rand(len(df_plays), len(columns_events[3:]))-2, columns =columns_events[3:])\n",
    "    df_plays_rep=df_plays_rep.append(df_plays.add(df_noise)).reset_index(drop=True)\n",
    "len(df_plays_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plays_rep.loc[0::40526]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more than 120k plays in our data set. We need now to include three new columns: the passing player, the receiving player and the flag \"offside/no_offside\". There are 22x22 = 484 possibilities, including the ball coming from the other team and the player keeping the ball. With our 120k plays, we could have a total of 58.843.752 different game situations. This might be a problem, so we are going to randomly select 25 possibilities instead of the 484, leaving us with close to 3 million game situations. For simplicity, the passing and receiving player will be defined by the order of the lineup, that is, these columns will be filled by numbers between 1 and 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_plays = df_plays_rep.copy()\n",
    "df_full_plays['pass'] = 0\n",
    "df_full_plays['rec'] = 0\n",
    "df_full_plays['offside'] = 0\n",
    "\n",
    "df_full = df_full_plays.copy()\n",
    "for ii in range(24):\n",
    "    df_full = df_full.append(df_full_plays)\n",
    "    \n",
    "passing = []\n",
    "receiving = []\n",
    "\n",
    "for ii in range(len(df_full)):\n",
    "    passing.append(random.randint(1,22))\n",
    "    receiving.append(random.randint(1,22))\n",
    "\n",
    "df_full['pass'] = passing\n",
    "df_full['rec'] = receiving\n",
    "\n",
    "len(df_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full.reset_index(drop=True)\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to annotate the data, determine if the play is an offside or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Annotation and Data set Balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A player is in an \"offside position\" if they are in the opposing team's half of the field and also \"nearer to the opponents' goal line than both the ball and the second-last opponent.\" This is a brief description, and we can develop it a little further by stating the five conditions that must be met.\n",
    "\n",
    "1. A teammate touches the ball, either by a pass, a headbutt or kicking towards the goal;\n",
    "2. The pass is not from a corner kick, a goal kick or a throw-in;\n",
    "3. The receiving player is in the offensive half of the field;\n",
    "4. The receiving player is closer to the goal line than the ball;\n",
    "5. There is only one player from the other team between the receiving player and the goal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all five conditions happen in a given play, the game must be stopped and a free kick is given to the defensive team.\n",
    "We need to include two new conditions:\n",
    "\n",
    "6. The receiving player is not the same as the passing one. This means the player can keep the ball to himself even if the above conditions happen.\n",
    "7. The receiving player must be in the field. The passing player can be outside, when we consider the play a throw-in or a corner kick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each game situation previously created, we will evaluate these 7 conditions. The offsides are a small subset of the total plays. Besides checking for offsides, we are creating a number of groups to help creating a more balanced dataset:\n",
    "1. when all 7 conditions are met, the offsides;\n",
    "2. when just one of the other conditions is not met, the \"close call\" non offsides, but excluding condition 5;\n",
    "3. when the only condition avoiding an offside is the number of players between the receiving player and the goal line, condition 5, the most recurring one;\n",
    "4. when all 7 conditions aren't met;\n",
    "5. all the other non offside cases.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many cases are in each of these groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsides = []\n",
    "zeroconditions = []\n",
    "condition1 = []\n",
    "condition2 = []\n",
    "condition3 = []\n",
    "condition4 = []\n",
    "condition5 = []\n",
    "condition6 = []\n",
    "condition7 = []\n",
    "\n",
    "for ii in range(len(df_full)):\n",
    "    \n",
    "    if ii%100000 == 0:\n",
    "        print('Analysing: ',ii)\n",
    "    \n",
    "    offsidemark = []\n",
    "    \n",
    "    receiver_team = int(df_full.loc[ii]['rec']/12)\n",
    "    passer_team = int(df_full.loc[ii]['pass']/12)\n",
    "    receiver = str(lineup[int(df_full.loc[ii]['rec'])])\n",
    "    passer = str(lineup[int(df_full.loc[ii]['pass'])])\n",
    "    \n",
    "    #condition1: \n",
    "    #A teammate touches the ball, either by a pass, a headbutt or kicking towards the goal.\n",
    "    #check to see if pass and rec are from the same team\n",
    "    if receiver_team == passer_team:\n",
    "        offsidemark.append(1)\n",
    "    else:\n",
    "        offsidemark.append(0)\n",
    "    \n",
    "    #condition2: \n",
    "    #The pass is not from a corner kick, a goal kick or a throw-in.\n",
    "    #check to see if passing player is outside the field\n",
    "    \n",
    "    if ((df_full.loc[ii]['x_'+passer] < -52) or (df_full.loc[ii]['x_'+passer] > 52) or (df_full.loc[ii]['y_'+passer] < -34) or (df_full.loc[ii]['y_'+passer] > 34)):\n",
    "        offsidemark.append(0)\n",
    "    else:\n",
    "        offsidemark.append(1)\n",
    "\n",
    "    #condition3: \n",
    "    #The receiving player is in the offensive half of the field.\n",
    "    #check to see if receiving player is on the offensive half\n",
    "    \n",
    "    if (((df_full.loc[ii]['x_'+receiver] > 0) and (receiver_team == 0)) or ((df_full.loc[ii]['x_'+receiver] < 0) and (receiver_team == 1))):\n",
    "        offsidemark.append(1)\n",
    "    else:\n",
    "        offsidemark.append(0)\n",
    "        \n",
    "    #condition4: \n",
    "    #The receiving player is closer to the goal line than the ball.\n",
    "    #check to see if receiving player is ahead of the passing player\n",
    "        \n",
    "    #team1 attacks to the right\n",
    "    if ((receiver_team == 0) and (df_full.loc[ii]['x_'+receiver] > df_full.loc[ii]['x_'+passer])):\n",
    "        offsidemark.append(1)\n",
    "    #team2 attacks to the left\n",
    "    elif ((receiver_team == 1) and (df_full.loc[ii]['x_'+receiver] < df_full.loc[ii]['x_'+passer])):\n",
    "        offsidemark.append(1)\n",
    "    else:\n",
    "        offsidemark.append(0)\n",
    "    \n",
    "    #condition5: \n",
    "    #There is only one player from the other team between the receiving player and the goal line.\n",
    "    #count how many players from the other team are between receiving playear and the goal line\n",
    "    \n",
    "    if (receiver_team == 0):\n",
    "        count_ahead = 0\n",
    "        for jj in range(22,2*len(lineup),2):\n",
    "            if df_full.iloc[ii,jj] > df_full.loc[ii]['x_'+receiver]:\n",
    "                count_ahead += 1\n",
    "            \n",
    "    if (receiver_team == 1):\n",
    "        count_ahead = 0\n",
    "        for jj in range(0,22,2):\n",
    "            if df_full.iloc[ii,jj] < df_full.loc[ii]['x_'+receiver]:\n",
    "                count_ahead += 1\n",
    "    \n",
    "    if count_ahead < 2:\n",
    "        offsidemark.append(1)\n",
    "    else:\n",
    "        offsidemark.append(0)\n",
    "    \n",
    "    \n",
    "    #condition6: \n",
    "    #The receiving player is not the same as the passing one\n",
    "    #check to see receiver == passer\n",
    "    \n",
    "    if passer == receiver:\n",
    "        offsidemark.append(0)\n",
    "    else:\n",
    "        offsidemark.append(1)\n",
    "\n",
    "    #condition7: \n",
    "    #The receiving player must be in the field\n",
    "    #check to see if receiving player is outside the field\n",
    "    \n",
    "    if ((df_full.loc[ii]['x_'+receiver] < -52) or (df_full.loc[ii]['x_'+receiver] > 52) or (df_full.loc[ii]['y_'+receiver] < -34) or (df_full.loc[ii]['y_'+receiver] > 34)):\n",
    "        offsidemark.append(0)\n",
    "    else:\n",
    "        offsidemark.append(1)\n",
    "        \n",
    "\n",
    "    #now we check all the conditions and group the cases\n",
    "    \n",
    "    #when all conditions are met\n",
    "    if sum(offsidemark) == 7:\n",
    "        offsides.append(ii)\n",
    "    \n",
    "    #when no conditions are met\n",
    "    if sum(offsidemark) == 0:\n",
    "        zeroconditions.append(ii)\n",
    "        \n",
    "    #when just one of the conditions isn't met\n",
    "    if sum(offsidemark) == 6:\n",
    "        if offsidemark[0] == 0:\n",
    "            condition1.append(ii)\n",
    "        if offsidemark[1] == 0:\n",
    "            condition2.append(ii)\n",
    "        if offsidemark[2] == 0:\n",
    "            condition3.append(ii)\n",
    "        if offsidemark[3] == 0:\n",
    "            condition4.append(ii)\n",
    "        if offsidemark[4] == 0:\n",
    "            condition5.append(ii)\n",
    "        if offsidemark[5] == 0:\n",
    "            condition6.append(ii)\n",
    "        if offsidemark[6] == 0:\n",
    "            condition7.append(ii)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number offsides: ',len(offsides))\n",
    "print('Number of cases with zero conditions: ',len(zeroconditions))\n",
    "print('Number of cases without condition 1: ',len(condition1))\n",
    "print('Number of cases without condition 2: ',len(condition2))\n",
    "print('Number of cases without condition 3: ',len(condition3))\n",
    "print('Number of cases without condition 4: ',len(condition4))\n",
    "print('Number of cases without condition 5: ',len(condition5))\n",
    "print('Number of cases without condition 6: ',len(condition6))\n",
    "print('Number of cases without condition 7: ',len(condition7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 3 million plays, close to 45 thousand are offsides. Let's start our final dataset by getting all the cases without one of the conditions, excluding the 5th, and the ones with zero conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = condition1.copy()\n",
    "if len(condition2)>0:\n",
    "    final_list.extend(condition2)\n",
    "if len(condition3)>0:\n",
    "    final_list.extend(condition3)\n",
    "if len(condition4)>0:\n",
    "    final_list.extend(condition4)\n",
    "if len(condition6)>0:\n",
    "    final_list.extend(condition6)\n",
    "if len(condition7)>0:\n",
    "    final_list.extend(condition7)\n",
    "if len(zeroconditions)>0:\n",
    "    final_list.extend(zeroconditions)\n",
    "\n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the 341.528 cases for the condition 5, we will select the same number above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list.extend(random.sample(condition5,len(final_list)))\n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mapped 427.610 cases on our classification above. That means there are more than 2.5 million other situations. We will pick the same number above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biglist = set([*range(len(df_full))])\n",
    "biglist = biglist.difference(offsides)\n",
    "biglist = biglist.difference(zeroconditions)\n",
    "biglist = biglist.difference(condition1)\n",
    "biglist = biglist.difference(condition2)\n",
    "biglist = biglist.difference(condition3)\n",
    "biglist = biglist.difference(condition4)\n",
    "biglist = biglist.difference(condition5)\n",
    "biglist = biglist.difference(condition6)\n",
    "biglist = biglist.difference(condition7)\n",
    "\n",
    "len(biglist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list.extend(random.sample(biglist,len(final_list)))\n",
    "len(final_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 165.468 plays where there is no offside. We need the same number of offsides, but we only have 44.715. A second round of data augmentation is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Second Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to increase the number of plays with offsides. The solution is quite simple: excluding throw-ins and corner kicks, the conditions are independent of Y. We will generate new plays by altering the position y for the players not involved in the play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repetition = 3\n",
    "df_offsides = df_full.loc[offsides].copy()\n",
    "for ii in range(repetition):\n",
    "    df_offsides1 = df_full.loc[offsides].copy()\n",
    "    for jj in range(len(offsides)):\n",
    "        receiver = str(lineup[int(df_offsides1.iloc[jj]['rec'])])\n",
    "        passer = str(lineup[int(df_offsides1.iloc[jj]['pass'])])\n",
    "        for kk in df_offsides1.columns:\n",
    "            if (kk[:2] == 'y_') and (kk[2:] != receiver) and (kk[:2] != passer):\n",
    "                df_offsides1.iloc[jj][kk] = df_offsides1.iloc[jj][kk] + 4*np.random.rand() -2\n",
    "    df_offsides = df_offsides.append(df_offsides1).reset_index(drop=True)\n",
    "\n",
    "df_offsides['offside']=1\n",
    "len(df_offsides)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this group, we will pick the same number of cases we have on our final list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_full.loc[final_list].copy()\n",
    "sample_offsides = random.sample([*range(len(df_offsides))],len(final_list))\n",
    "df_final = df_final.append(df_offsides.loc[sample_offsides]).reset_index(drop=True)\n",
    "len(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data set is ready! We have 330.936 plays, with half of them offsides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, let's take a look at some random plays to see if everything is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_offside(index):\n",
    "    #getting data for the teams\n",
    "    receiver = str(lineup[int(df_final.loc[index,'rec'])])\n",
    "    passer = str(lineup[int(df_final.loc[index,'pass'])])\n",
    "    \n",
    "    g0 = (100*df_final.loc[index,'x_'+receiver],100*df_final.loc[index,'y_'+receiver])\n",
    "    g1 = (100*df_final.loc[index,'x_'+passer],100*df_final.loc[index,'y_'+passer])\n",
    "    g2 = (100*df_final.loc[index,columns_events[3:25:2]],100*df_final.loc[index,columns_events[4:25:2]])\n",
    "    g3 = (100*df_final.loc[index,columns_events[25:47:2]],100*df_final.loc[index,columns_events[26:48:2]])\n",
    "    data = (g0,g1,g2,g3)\n",
    "    colors = (\"green\",\"purple\",\"red\", \"blue\")\n",
    "    groups = (\"receiver\",\"passer\",\"team1\", \"team2\")\n",
    "    size=(90,90,30,30)\n",
    "\n",
    "    # Create plot\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    plt.scatter(fieldx,fieldy,s=5,c=\"black\",alpha=0.3)    \n",
    "\n",
    "    for data, color, group, size in zip(data, colors, groups, size):\n",
    "        x, y = data\n",
    "        ax.scatter(x, y, alpha=0.8, c=color, edgecolors='none', s=size, label=group)\n",
    "\n",
    "    plt.ylim(-3700, 3700)\n",
    "    plt.xlim(-5500, 5500)\n",
    "    if df_final.iloc[index]['offside'] == 1:\n",
    "        plt.title('Time frame: '+str(index)+\", OFFSIDE\")\n",
    "    else:\n",
    "        plt.title('Time frame: '+str(index)+\", NO OFFSIDE\")\n",
    "            \n",
    "    plt.legend(loc=2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_offside(random.randint(0, len(df_final)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different classification models will be evaluated: **Random Forest** and **Support Vector Classifier**. For the RF model, we will vary the number of decision trees (1, 10, 100, 1.000 and 10.000). For the SVC model, much more computer demanding, we will vary the size of the training set (25%, 50% and, hopefully, 75%).\n",
    "At the end, we will compare their performances using ROC, Accuracy and Confusion Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two sets of data, the features and the labels. A training set with 75% of the data will be used to generate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_final = pd.read_csv('df_final.csv')\n",
    "labels = df_final['offside']\n",
    "features = df_final.drop('offside',axis=1)\n",
    "feature_list = list(features.columns)\n",
    "features = np.array(features)\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Five different Random Forest models will be generated, with 1, 10, 100, 1.000 and 10.000 trees. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc=[]\n",
    "accuracy=[]\n",
    "errors=[]\n",
    "confusion=[]\n",
    "for i in range(5):\n",
    "    print('Number of trees: ',10**i)\n",
    "    print('Classify data')\n",
    "    rfc=RandomForestClassifier(n_estimators=10**i,random_state=0)\n",
    "    rfc.fit(train_features,train_labels)\n",
    "    pred_labels=rfc.predict(test_features)\n",
    "    \n",
    "    print('Measure results')\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, pred_labels)\n",
    "    roc_auc.append(auc(false_positive_rate, true_positive_rate))\n",
    "    \n",
    "    accuracy.append(metrics.accuracy_score(test_labels,pred_labels))\n",
    "    errors.append(abs(pred_labels - test_labels)/len(test_labels))\n",
    "    confusion.append(metrics.confusion_matrix(test_labels,pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc1=[]\n",
    "accuracy1=[]\n",
    "confusion1=[]\n",
    "for ii in range(3,0,-1):\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25*ii, random_state = 42)\n",
    "    print('Classify data')\n",
    "    svc=svm.SVC(random_state=0)\n",
    "    svc.fit(train_features,train_labels)\n",
    "    pred_labels=svc.predict(test_features)\n",
    "    \n",
    "    print('Measure results')\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(test_labels, pred_labels)\n",
    "    roc_auc1.append(auc(false_positive_rate, true_positive_rate))\n",
    "    \n",
    "    accuracy1.append(metrics.accuracy_score(test_labels,pred_labels))\n",
    "    confusion1.append(metrics.confusion_matrix(test_labels,pred_labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To our surprise, the **Random Forest Classifier with 1.000 trees**, was the best model! We were expecting the SVC to be a better fit, because the offside conditions use the relative position of the players and a higher dimensional method would be able to get a better understanding of the data.\n",
    "\n",
    "When we compare the best RF to the best SVC, our RF performance is way better, with an error smaller than 2%! Very impressive result with such a simple model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final conclusion: we created a model to make a decision based on the position of the players without explicitly setting the rules with an accuracy of 98.5%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
